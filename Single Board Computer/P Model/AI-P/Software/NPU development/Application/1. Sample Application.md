# 1. Sample Application

This chapter is guiding document for NPU Sample Application.

The TOPST AI SDK provides a sample Application to verify NPU
functionality named ‘tc-nn-app’.

This NPU Sample Application uses Camera, Image Files, and PC Stream as
inputs to output NPU image processing results to LCD, File, and PC
Stream.

<br/><br/>

## 1.1 Overview

NPU Sample Application can only perform Neural Process Unit (NPU)
operations.

The tc-nn-app architecture as shown below.

<p align="center"><img src="https://github.com/topst-development/Documentation/blob/main/TOPST-AI/Software/media/1. Sample Application.image1.png?raw=true"
style="width:7.27639in;height:1.15694in"</p>


<p align="center"><strong>Figure 1.1 Architecture of tc-nn-app</strong></p>

<br/><br/>

## 1.2 NPU Sample Application Code

You can get a sample code to do the NPU test in the TOP AI SDK.

- {TOPST_PATH}/build/tcc7500-main/tmp/work/cortexa53-telechips-linux/tc-nn-app/1.0.0-r0/git/

<table>
<colgroup>
<col style="width: 100%" />
</colgroup>
<tbody>
<tr class="odd">
<td><p><strong>├── dewarp</strong></p>
<p><strong>│   ├── NnDeWarp.c</strong></p>
<p><strong>│   └── NnDeWarp.h</strong></p>
<p><strong>├── encoder</strong></p>
<p><strong>│   ├── NnEncoder.c</strong></p>
<p><strong>│   ├── NnEncoder.h</strong></p>
<p><strong>├── include</strong></p>
<p><strong>│   ├── NnAppMain.h</strong></p>
<p><strong>│   ├── NnCv.h</strong></p>
<p><strong>│   ├── NnDataType.h</strong></p>
<p><strong>│   ├── NnDebug.h</strong></p>
<p><strong>│   ├── NnError.h</strong></p>
<p><strong>│   ├── NnInference.h</strong></p>
<p><strong>│   ├── NnInputCapture.h</strong></p>
<p><strong>│   ├── NnPreProcess.h</strong></p>
<p><strong>│   ├── NnProtocolManager.h</strong></p>
<p><strong>│   ├── NnReservedMemory.h</strong></p>
<p><strong>│   ├── NnRtpmManager.h</strong></p>
<p><strong>│   └── NnVisualize.h</strong></p>
<p><strong>├── npu</strong></p>
<p><strong>│    ├── npu_api.c</strong></p>
<p><strong>│   ├── npu_api_ex.c</strong></p>
<p><strong>│   ├── npu_api.h</strong></p>
<p><strong>│   └── npu_api_mem.c</strong></p>
<p><strong>└── src</strong></p>
<p><strong>├── NnAppMain.c</strong></p>
<p><strong>├── NnCv.cpp</strong></p>
<p><strong>├── NnDebug.c</strong></p>
<p><strong>├── NnInference.c</strong></p>
<p><strong>├── NnInputCapture.c</strong></p>
<p><strong>├── NnPreProcess.c</strong></p>
<p><strong>├── NnProtocolManager.c</strong></p>
<p><strong>├── NnReservedMemory.c</strong></p>
<p><strong>├── NnRtpmManager.c</strong></p>
<p><strong>└── NnVisualize.c</strong></p></td>
</tr>
</tbody>
</table>

<br/>

**Table 1.1 Structure and Description:**

|  Directory    |                      Description                       |
|---------------|--------------------------------------------------------|
| dewarp        | Dewarp Source directory                                |
| encoder       | Encoding camera video Source directory                 |
| npu           | NPU Device Driver & Network Lib(.so) Interface Source. |
| src           | Main Source directory.                                 |

<br/>

### 1.2.1 Functions and Descriptions for Application

Table 1.2 is the functions for the operation of the NPU Sample
Application and its explanation.

When creating an application using NPU, you can refer to the function in
Table 1.2.

<br/>

**Table 1.2 Functions and Descriptions:**

<table>
<colgroup>
<col style="width: 19%" />
<col style="width: 27%" />
<col style="width: 53%" />
</colgroup>
<tbody>
<tr class="odd">
<td><strong>Name</strong></td>
<td><strong>Function</strong></td>
<td><strong>Description</strong></td>
</tr>
<tr class="even">
<td rowspan="7">src/NnAppMain.c</td>
<td>NnparseArgs ()</td>
<td>Option Parsing</td>
</tr>
<tr class="odd">
<td><p>InputcaptureOpenDevice ()</p>
<p>InputcaptureSetConfig ()</p></td>
<td><p>Camera Device Configuration</p>
<p>(Device Open, Input Size, Input Format)</p></td>
</tr>
<tr class="even">
<td>VisualizeOpenDevice ()</td>
<td>Display Output use Overlay Device</td>
</tr>
<tr class="odd">
<td>InferenceInit ()</td>
<td>Network(NPU Device) Initialize</td>
</tr>
<tr class="even">
<td>InputcaptureGetBuffer ()</td>
<td>Get Camera Data</td>
</tr>
<tr class="odd">
<td>cvDrawFPS ()<br />
cvDrawMemInfio ()<br />
cvDrawNpuInfo1 ()<br />
cvDrawNpuInfo2 ()</td>
<td>Draw the results with OpenCV</td>
</tr>
<tr class="even">
<td>VisuallizeShow ()</td>
<td>Result Output with Display</td>
</tr>
<tr class="odd">
<td rowspan="2">src/NnInference.c</td>
<td>InferenceInit ()</td>
<td><p>Open NPU Device. And Load network file</p>
<p>(network CMD, network Param)</p></td>
</tr>
<tr class="even">
<td>InferenceRun ()</td>
<td><p>After executing inference, tensor data is obtained.</p>
<p>Tensor data is delivered to net.so,</p>
<p>and net.so performs Object detection</p></td>
</tr>
<tr class="odd">
<td rowspan="4">src/npu_api.c</td>
<td>npu_open ()</td>
<td>Open NPU device driver</td>
</tr>
<tr class="even">
<td>network_load ():</td>
<td><p>Pass the network cmd.bin and qunatized_network.bin files</p>
<p>as parameters, create a network instance</p>
<p>with network information,</p>
<p>and return the fd that can access it.</p></td>
</tr>
<tr class="odd">
<td>buffer_alloc ()</td>
<td>Creates CMA buffer for input/output</td>
</tr>
<tr class="even">
<td>network_profile ()</td>
<td>Inference is executed using the input/output buffer passed through
net_run_req. Return the cycle required until the NPU operation is
completed.</td>
</tr>
</tbody>
</table>

<br/>

### 1.2.2 Operation Flow Chart

Figure 1.2 is the process of using NPU in the NPU Sample Application.

You can refer to this flow when creating an application using NPU.

<p align="center"><img src="https://github.com/topst-development/Documentation/blob/main/TOPST-AI/Software/media/1. Sample Application.image2.png?raw=true"
style="width:5.9375in;height:5.36857in"</p>

<p align="center"><strong>Figure 1.2 NPU Operation Flow Charr</strong></p>

<br/><br/>

## 1.3 Run NPU Sample Application

<br/>

### 1.3.1 tc-nn-app Options

Options provided by **tc-nn-app** are shown in the table below.

<br/>

**Table 1.3 tc-nn-app Options:**

<table>
<colgroup>
<col style="width: 12%" />
<col style="width: 7%" />
<col style="width: 7%" />
<col style="width: 13%" />
<col style="width: 13%" />
<col style="width: 44%" />
</colgroup>
<tbody>
<tr class="odd">
<td><strong>Name</strong></td>
<td><strong>Option</strong></td>
<td><strong>Range</strong></td>
<td><strong>Default</strong></td>
<td><strong>Example</strong></td>
<td><strong>Description</strong></td>
</tr>
<tr class="even">
<td>Network Mode</td>
<td>-m</td>
<td><p>On</p>
<p>off</p></td>
<td>on</td>
<td><p>-m on</p>
<p>-m off</p></td>
<td><p>on: A neural network inference mode.</p>
<p>off: Camera preview mode</p></td>
</tr>
<tr class="odd">
<td>Network1 Path</td>
<td>-n</td>
<td></td>
<td>/usr/share/yolo v3_tiny_quanti zed</td>
<td>-n /usr/share/yol ov3_tiny_quant ized</td>
<td>A mode for specifying the neural network of network 1.</td>
</tr>
<tr class="even">
<td>Network1 NPU Index</td>
<td>-d</td>
<td>0 1</td>
<td>0</td>
<td>
  -d 0  
  <br/>
  -d 1
</td>
<td>A mode for specifying the NPU index of network</td>
</tr>
<tr class="odd">
<td>Network2 Path</td>
<td>-N</td>
<td></td>
<td>/usr/share/mo bilenetv2_7_qu antized/</td>
<td>-N /usr/share/ mobilenetv2_7_ quantized/</td>
<td>A mode for specifying the neural network of network 2.</td>
</tr>
<tr class="even">
<td>Network2 NPU Index</td>
<td>-D</td>
<td>0 1</td>
<td>1</td>
<td>
  -D 0
  <br/>
  -D 1
</td>
<td>A mode for specifying the NPU index of network</td>
</tr>
<tr class="odd">
<td>Input Mode</td>
<td>-i</td>
<td>camera rtpm file</td>
<td>camera</td>
<td>
  -i camera
  <br/>
  -i rtpm
  <br/>
  -i file
</td>
<td><p>camera: A mode that takes input from the camera.</p>
<p>rtpm: A mode that takes input from the rtpm.</p>
<p>file: A mode that takes input from the image file.</p></td>
</tr>
<tr class="even">
<td>Output Mode</td>
<td>-o</td>
<td>display rtpm file</td>
<td>display</td>
<td>
  -o display
  <br/>
  -o rtpm
  <br/>
  -o file
</td>
<td><p>display: A mode that outputs to an LCD screen.</p>
<p>rtpm: A mode that outputs to rtpm.</p>
<p>file: A mode that outputs to an image file.</p></td>
</tr>
<tr class="odd">
<td>Input Width</td>
<td>-w</td>
<td>Up to 1920</td>
<td>1920</td>
<td>-w 1920</td>
<td>A mode for specifying the width of the input.</td>
</tr>
<tr class="even">
<td>Input Height</td>
<td>-h</td>
<td>Up to 1080</td>
<td>1080</td>
<td>-h 1080</td>
<td>A mode for specifying the height of the input.</td>
</tr>
<tr class="odd">
<td>Output Width</td>
<td>-W</td>
<td>Up to 1920</td>
<td>1920</td>
<td>-W 1920</td>
<td>A mode for specifying the width of the output.</td>
</tr>
<tr class="even">
<td>Output Height</td>
<td>-H</td>
<td>Up to 720</td>
<td>720</td>
<td>-H 720</td>
<td>A mode for specifying the height of the output.</td>
</tr>
<tr class="odd">
<td>Input Path</td>
<td>-p</td>
<td></td>
<td>/dev/video0</td>
<td>-p /dev/video0</td>
<td>A mode for specifying the input path.</td>
</tr>
<tr class="even">
<td>Output Path</td>
<td>-P</td>
<td></td>
<td>/dev/overlay</td>
<td>-P /dev/overlay</td>
<td>A mode for specifying the output path</td>
</tr>
<tr class="odd">
<td>Encoding Mode</td>
<td>-E</td>
<td></td>
<td>20</td>
<td>-E 20</td>
<td>A mode for encoding camera video</td>
</tr>
<tr class="even">
<td>Debug Mode</td>
<td>-g</td>
<td>off log file</td>
<td>off</td>
<td>
  -g off
  <br/>
  -g log
  <br/>
  -g file
</td>
<td><p>off: A mode that runs without debugging.</p>
<p>log: A mode that outputs debugging information as logs.</p>
<p>file: A mode that saves debugging information to a file.</p></td>
</tr>
</tbody>
</table>

<br/>

### 1.3.2 Run tc-nn-app

The example of running **tc-nn-app** is as follows.

<br/>

<table align="center">
<colgroup>
<col style="width: 100%" />
</colgroup>
<tbody>
<tr class="odd">
<td><p><strong>$ tcnnapp -p /dev/video0 -W 800 -H 480 -w 1920 -h
1080</strong></p>
<p>----------------Parameter Info----------------</p>
<p>[Network1]Network Path : /usr/share/yolov3_tiny_quantized/</p>
<p>[Network1]NPU Index : 0</p>
<p>[Network2]Network Path : /usr/share/mobilenetv2_7_quantized/</p>
<p>[Network2]NPU Index : 1</p>
<p>[Common]Input Mode : camera</p>
<p>[Common]Output Mode : display</p>
<p>[Common]Input Size : 1920 x 1080</p>
<p>[Common]Output Size : 800 x 480</p>
<p>[Common]Input Path : /dev/video0</p>
<p>[Common]Output Path : /dev/overlay</p>
<p>[Common]Input Format : ARGB8888</p>
<p>[Common]Output Format : RGB888</p>
<p>----------------Parameter End----------------</p></td>
</tr>
</tbody>
</table>

<br/>

<p align="center"><img src="https://github.com/topst-development/Documentation/blob/main/TOPST-AI/Software/media/1. Sample Application.image3.jpeg?raw=true"
style="width:4.68611in;height:3.14028in"
alt="스크린샷, 텍스트, 실내이(가) 표시된 사진 자동 생성된 설명" /></p>

<p align="center"><strong>Figure 1.3 tc-nn-app Execution Screen</strong></p>
