# 4. Build Guide

<br/><br/>

## 4.1 Converter

The Converter reads neural network file and converts it into ”bin”
file, which is network file format used in TOPST AI NPU SW Toolkit.
And it also performs network inferences and collects statistics of
activation data, which are used later for network quantization.

<br/>

<strong>1.  Darknet</strong>

```
$ python ./EnlightSDK/converter.py \
  ./input_networks/yolov4.cfg \
  --weight ./input_networks/yolov4.weights \
  --type obj \
  --dataset Custom \
  --dataset-root my_dataset_path \
  --output ./output_networks/yolov4.enlight \
  --enable-track \
  --mean 0 0 0 \
  --std 1 1 1 \
  --num-class 90
```

<br/>

<table>
<colgroup>
<col style="width: 47%" />
<col style="width: 52%" />
</colgroup>
<tbody>
<tr class="odd">
<td>./input_networks/yolov4.cfg</td>
<td>Input network file name</td>
</tr>
<tr class="even">
<td>--weight ./input_networks/yolov4.weights</td>
<td>Darknet weights file name</td>
</tr>
<tr class="odd">
<td>--type obj</td>
<td><p>Type of post-processing:</p>
<p>classification (class),</p>
<p>object detection (obj),</p>
<p>or unknown (unknown)</p></td>
</tr>
<tr class="even">
<td>--dataset Custom</td>
<td>Custom: user defined dataset</td>
</tr>
<tr class="odd">
<td>--dataset-root ./my_dataset_path</td>
<td><p>Path to Input data which are used for</p>
<p>gathering activation statistics</p></td>
</tr>
<tr class="even">
<td>--output ./output_networks/yolov4.enlight</td>
<td>Converter output file name</td>
</tr>
<tr class="odd">
<td>--enable-track</td>
<td>Enable to gather activation statistics</td>
</tr>
<tr class="even">
<td>--mean 0 0 0</td>
<td>mean values of input normalization (RGB)</td>
</tr>
<tr class="odd">
<td>--std 1 1 1</td>
<td>std values of input normalization (RGB)</td>
</tr>
<tr class="even">
<td>--num-class 90</td>
<td>object class number</td>
</tr>
</tbody>
</table>

<br/>

<strong>2.  TensorFlow Lite</strong>

```
$ python ./EnlightSDK/converter.py \
  ./input_networks/lite-model_ssd_mobilenet_v1_100_320_fp32_nms_1.tflite \
  --type obj \
  --dataset Custom \
  --dataset-root my_dataset_path \
  --output ./output_networks/lite-model_ssd_mobilenet_v1_100_320_fp32_nms_1.enlight \
  --enable-track \
  --mean 0.5 0.5 0.5 \
  --std 0.5 0.5 0.5 \
  --num-class 90
```

<br/>

<table>
<colgroup>
<col style="width: 58%" />
<col style="width: 41%" />
</colgroup>
<tbody>
<tr class="odd">
<td>./input_networks/lite-model_ssd_mobilenet_v1_100_320_fp32_nms_1.tflite</td>
<td>Input network file name</td>
</tr>
<tr class="even">
<td>--type obj</td>
<td><p>Type of post-processing:</p>
<p>classification (class),</p>
<p>object detection (obj),</p>
<p>or unknown (unknown)</p></td>
</tr>
<tr class="odd">
<td>--dataset Custom</td>
<td>Custom: user defined dataset</td>
</tr>
<tr class="even">
<td>--dataset-root ./my_dataset_path</td>
<td><p>Path to Input data which are used for</p>
<p>gathering activation statistics</p></td>
</tr>
<tr class="odd">
<td>--output
./output_networks/lite-model_ssd_mobilenet_v1_100_320_fp32_nms_1.enlight</td>
<td>Converter output file name</td>
</tr>
<tr class="even">
<td>--enable-track</td>
<td>Enable to gather activation statistics</td>
</tr>
<tr class="odd">
<td>--mean 0.5 0.5 0.5</td>
<td>mean values of input normalization (RGB)</td>
</tr>
<tr class="even">
<td>--std 0.5 0.5 0.5</td>
<td>std values of input normalization (RGB)</td>
</tr>
<tr class="odd">
<td>--num-class 90</td>
<td>object class number</td>
</tr>
</tbody>
</table>

<br/>

<strong>3.  ONNX</strong>

```
$ python ./EnlightSDK/converter.py
  ./input_networks/mb2-ssd-lite.onnx \
  --type obj \
  --add-detection-post-process ./input_networks/mb2-ssd-lite.anchor \
  --logistic softmax \
  --dataset Custom \
  --dataset-root my_dataset_path \
  --output ./output_networks/mb2-ssd-lite.enlight \
  --enable-track \
  --mean 0.498 0.498 0.498 \
  --std 0.502 0.502 0.502 \
  --num-class 20 \
  --variance 0.1 0.2
```

<br/>

<table>
<colgroup>
<col style="width: 58%" />
<col style="width: 41%" />
</colgroup>
<tbody>
<tr class="odd">
<td>./input_networks/mb2-ssd-lite.onnx</td>
<td>Input network file name</td>
</tr>
<tr class="even">
<td>--type obj</td>
<td><p>Type of post-processing:</p>
<p>classification (class),</p>
<p>object detection (obj),</p>
<p>or unknown (unknown)</p></td>
</tr>
<tr class="odd">
<td>--add-detection-post-process
./input_networks/mb2-ssd-lite.anchor</td>
<td>Default box file name</td>
</tr>
<tr class="even">
<td>--logistic softmax</td>
<td><p>Logistic function in post process:</p>
<p>softmax, sigmoid, none</p></td>
</tr>
<tr class="odd">
<td>--dataset Custom</td>
<td>Custom: user defined dataset</td>
</tr>
<tr class="even">
<td>--dataset-root ./my_dataset_path</td>
<td><p>Path to Input data which are used for</p>
<p>gathering activation statistics</p></td>
</tr>
<tr class="odd">
<td>--output ./output_networks/mb2-ssd-lite.enlight</td>
<td>Converter output file name</td>
</tr>
<tr class="even">
<td>--enable-track</td>
<td>Enable to gather activation statistics</td>
</tr>
<tr class="odd">
<td>--mean 0.498 0.498 0.498</td>
<td>mean values of input normalization (RGB)</td>
</tr>
<tr class="even">
<td>--std 0.502 0.502 0.502</td>
<td>std values of input normalization (RGB)</td>
</tr>
<tr class="odd">
<td>--num-class 20</td>
<td>object class number</td>
</tr>
<tr class="even">
<td>--variance 0.1 0.2</td>
<td>Variance of x and y for SSD detection layer</td>
</tr>
</tbody>
</table>

<br/><br/>

## 4.2 Quantizer

The Quantizer converts the original network model based on floating
point operations into integer-based (quantized) network.

<br/>

**1.  Darknet**

```
$ python ./EnlightSDK/quantizer.py \
  ./output_networks/yolov4.enlight \
  --output ./output_networks/yolov4_quantized.enlight
```

<br/>

**2.  TensorFlow Lite**

```
$ python ./EnlightSDK/quantizer.py \
  ./output_networks/lite-model_ssd_mobilenet_v1_100_320_fp32_nms_1.enlight \
  --output ./output_networks/lite-model_ssd_mobilenet_v1_100_320_fp32_nms_1_quantized.enlight
```

<br/>

**3.  ONNX**

```
$ python ./EnlightSDK/quantizer.py \
  ./output_networks/mb2-ssd-lite.enlight \
  --output ./output_networks/mb2-ssd-lite_quantized.enlight
```

<br/><br/>

## 4.3 Compiler

The Compiler compiles a quantized neural network into NPU codes and
network parameters for processing neural networks on TOPST NPU HW.

<br/>

**1.  Darknet**

```
$ python ./EnlightSDK/compiler.py \
  ./output_networks/yolov4_quantized.enlight \
  --th-iou 0.5 \
  --th-conf 0.5
```

<br/>

**2.  TensorFlow Lite**

```
$ python ./EnlightSDK/compiler.py \
  ./output_networks/lite-model_ssd_mobilenet_v1_100_320_fp32_nms_1_quantized.enlight \
  --th-iou 0.5 \
  --th-conf 0.5
```

<br/>

**3.  ONNX**

```
$ python ./EnlightSDK/compiler.py \
  ./output_networks/mb2-ssd-lite_quantized.enlight \
  --th-iou 0.5 \
  --th-conf 0.5
```

<br/>

<table>
<colgroup>
<col style="width: 51%" />
<col style="width: 48%" />
</colgroup>
<tbody>
<tr class="odd">
<td>--th-iou 0.5</td>
<td><p>IOU threshold.</p>
<p>Valid only for detection neural network.</p></td>
</tr>
<tr class="even">
<td>--th-conf 0.5</td>
<td><p>Confidence threshold.</p>
<p>Valid only for detection neural network.</p></td>
</tr>
</tbody>
</table>

<br/>

The generated files are stored in “output_code/\<network_name\>”
directory.

Compiler Output File:

- npu_cmd.bin: TELECHIPS NPU inference code
- quantized_network.bin: Network weight and bias parameters
- network.h: Buffers size and network parameters for post-process
- post_process.c: Post-process code
- Other files: Debugging information (internal only)

In neural network application, “npu_cmd.bin” and “quantized_network.bin”
are loaded into DMA buffers using TELECHIPS NPU APIs and Linux device
driver. “network.h” and “post_process.c” are built as network object
file (.so) as shown in Network Object Build.
