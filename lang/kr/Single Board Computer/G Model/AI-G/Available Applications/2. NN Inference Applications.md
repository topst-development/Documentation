# 1. 소개
---
이 문서는 AI-G SDK에 포함된 샘플 및 테스트 애플리케이션의 사용 가이드를 제공합니다. 이 애플리케이션들은 사용자가 AI-G의 온보드 NPU를 사용하여 AI 추론 기능을 이해하고 평가할 수 있도록 설계되었습니다.
이 문서는 다음 정보를 포함합니다:
- 샘플 애플리케이션
  - tcnnapp
  - tcnncameraapp
  - tcnputestapp
<br/><br/><br/><br/>
 
 
# 2. 샘플 애플리케이션
---
이 섹션에서는 AI-G SDK에서 제공하는 세 가지 샘플/테스트 애플리케이션에 대해 설명합니다. 각 애플리케이션은 사용자가 AI-G의 AI 기능을 평가하고 활용할 수 있도록 돕기 위해 설계되었습니다. 애플리케이션은 NPU 추론 테스트 및 실시간 카메라 입력과 같은 다양한 시나리오를 다룹니다.
<br/><br/><br/>
 
## 2.1 tcnnapp
---
tcnnapp은 AI-G 플랫폼에서 NPU를 사용하여 이미지 기반 추론을 수행하는 방법을 보여주는 샘플 AI 애플리케이션입니다. 다양한 입력/출력 모드를 지원하며 YOLOv5s 및 MobileNetv2와 같은 사전 학습된 모델을 사용한 객체 감지를 보여줍니다.
<br/><br/>
 
### 사용 사례 1. 기본 파일 간 추론 (File to File Inference)
이 사례는 로컬 이미지 파일에서 추론을 실행하고 결과를 출력 파일로 저장하는 방법을 보여줍니다. 이는 카메라나 디스플레이 하드웨어를 사용하지 않고 기본적인 기능 테스트 및 모델 검증을 수행하는 데 유용합니다.
추론을 위해 다음 명령을 입력하십시오:
```
$ tcnnapp -i file -p test.png -o file -P result.png
```
 
이 명령은 입력 이미지 파일(test.png)을 사용하여 tcnnapp을 실행하고 추론 결과를 출력 파일(result.png)에 저장합니다. 모델을 지정하지 않으면 애플리케이션은 자동으로 기본 양자화 모델인 YOLOv5s 및 MobileNetv2를 사용합니다.
결과는 다음과 같습니다:
<p align="center"><img src="https://raw.githubusercontent.com/topst-development/Documentation/refs/heads/main/Assets/TOPST%20AI-G/Available%20Applications/Figure%201.%20Inference%20Result.png"></p>
<p align="center"><strong>그림 2.1 추론 결과 </strong></p>
<br/><br/>
 
### 사용 사례 2. 카메라 및 디스플레이를 통한 실시간 추론
이 사례는 연결된 MIPI CSI 카메라와 MIPI DSI 디스플레이와 함께 tcnnapp을 사용하여 실시간 AI 추론을 수행하고 결과를 시각화하는 방법을 보여줍니다. 애플리케이션은 카메라에서 라이브 비디오 입력을 스트리밍하고, NPU에서 기본 양자화 모델(YOLOv5s 및 MobileNetv2)을 사용하여 실시간 추론을 수행하며, 결과를 화면에 표시합니다.
장치 연결은 다음과 같습니다:
<p align="center"><img src="https://raw.githubusercontent.com/topst-development/Documentation/refs/heads/main/Assets/TOPST%20AI-G/Available%20Applications/Figure%202.%20Device%20Connection.png" width="600"></p>
<p align="center"><strong>그림 2.2 AI-G의 카메라 및 디스플레이 연결 </strong></p><br/>
 
장치를 연결한 후 다음 명령을 입력하십시오:
```
$ tcnnapp -i camera -o display
```
이 명령은 CSI 카메라를 입력으로 사용하여 실시간 추론을 시작합니다. 캡처된 비디오 프레임은 객체 감지 및 분류 작업을 위해 NPU로 전달됩니다.
바운딩 박스, 클래스 레이블, 신뢰도 점수와 같은 추론 결과는 출력 프레임에 직접 렌더링됩니다.
이러한 주석이 달린 프레임은 5인치 DSI 디스플레이에 실시간으로 표시되어 즉각적인 시각적 피드백을 제공합니다.
 
시각적 출력 외에도 시스템은 CPU 사용량, NPU 활용률, 메모리 상태와 같은 주요 성능 지표를 기록하며, 이는 시리얼 콘솔이나 원격 인터페이스를 통해 모니터링할 수 있습니다.
 
결과는 다음과 같습니다:
<p align="center"><img src="https://raw.githubusercontent.com/topst-development/Documentation/refs/heads/main/Assets/TOPST%20AI-G/Software/NPU%20development/AI-G%20NPU%20toolkit/6.%20Sample%20Applictation.png" width="500"></p>
<p align="center"><strong>그림 2.3 추론 결과 </strong></p><br/>
 
<br/><br/>
 
### 사용 사례 3. 카메라 및 RTPM을 통한 실시간 추론
이 사례는 MIPI CSI 카메라를 입력으로, 실시간 성능 모니터(RTPM)를 출력 방법으로 사용하여 tcnnapp을 사용하는 방법을 보여줍니다. 이 애플리케이션은 카메라에서 라이브 비디오 입력을 스트리밍하고, NPU에서 기본 양자화 모델(YOLOv5s 및 MobileNetv2)을 사용하여 실시간 추론을 수행하며, 시각화 및 성능 모니터링을 위해 결과를 RTPM을 통해 PC로 전송합니다.
RTPM 툴킷은 PC 환경에서 AI-G의 출력을 모니터링하는 Python으로 개발된 GUI 기반 도구입니다. 이를 통해 추론 결과뿐만 아니라 CPU, NPU 및 메모리 사용량과 같은 시스템 성능 지표를 관찰할 수 있습니다.
 
**참고**: RTPM에 대한 자세한 내용은 Software 섹션의 RTPM.md를 참조하십시오.
 
장치 연결은 다음과 같습니다:
<p align="center"><img src="https://raw.githubusercontent.com/topst-development/Documentation/refs/heads/main/Assets/TOPST%20AI-G/Available%20Applications/Figure%204.%20Camera%20and%20RTPM%20Communication%20via%20AI-G.png"width="900"></p>
<p align="center"><strong>그림 2.4 AI-G를 통한 카메라 및 RTPM 통신 </strong></p><br/>
 
카메라를 연결한 후 다음 명령을 입력하십시오:
```
$ tcnnapp -i camera -o rtpm
```
 
이 명령은 CSI 카메라를 입력으로 사용하여 실시간 추론을 시작합니다. 감지된 객체 및 분류 레이블과 같은 추론 결과는 호스트 PC로 전송되어 RTPM 인터페이스를 통해 시각화됩니다.
추론 출력 외에도 RTPM은 CPU 사용량, NPU 부하 및 메모리 사용량을 포함한 시스템 성능 지표를 실시간으로 표시합니다.
결과는 다음과 같습니다:
<p align="center"><img src="https://raw.githubusercontent.com/topst-development/Documentation/refs/heads/main/Assets/TOPST%20AI-G/Available%20Applications/Figure%205.%20Inference%20Result.png"width="1600"></p>
<p align="center"><strong>그림 2.5 추론 결과 </strong></p>
<br/><br/>
 
### 사용 사례 4. RTPM 입력 및 출력을 통한 추론
이 사례는 RTPM을 통해 호스트 PC에서 스트리밍된 입력 이미지를 사용하여 추론을 실행하고, 추론 결과를 동일한 RTPM 인터페이스를 통해 디스플레이하기 위해 PC로 다시 전송하는 방법을 보여줍니다. 입력 데이터는 이미지 또는 비디오일 수 있습니다.
RTPM을 실행하려면 Software 섹션의 RTPM.md 문서를 참조하십시오. 그런 다음 다음 명령을 입력하십시오:
```
$ tcnnapp -i rtpm -o rtpm
```
이 명령은 RTPM을 입력 및 출력으로 모두 사용하여 tcnnapp을 실행합니다. 데이터는 RTPM을 통해 호스트 PC에서 전송되고, AI-G 보드의 NPU에 의해 처리되며, 추론 결과는 다시 PC로 전송되어 RTPM 인터페이스를 통해 표시됩니다.
결과는 다음과 같습니다:
<p align="center"><img src="https://raw.githubusercontent.com/topst-development/Documentation/refs/heads/main/Assets/TOPST%20AI-G/Available%20Applications/Figure%206.%20Inference%20Result.png"></p>
<p align="center"><strong>그림 2.6 추론 결과 </strong></p>
<br/><br/><br/>
 
## 2.2 tcnncameraapp
---
tcnncameraapp은 AI-G 플랫폼에서 지원되는 카메라 모듈을 테스트하고 미리 볼 수 있는 샘플 애플리케이션입니다. Video4Linux2 (V4L2) 프레임워크를 기반으로 구축되었으며 연결된 MIPI CSI 인터페이스 및 DSI 디스플레이를 통해 실시간 카메라 미리보기를 활성화합니다.
이 애플리케이션은 주로 카메라 기능 검증, 디스플레이 출력 테스트 및 이미지 신호 품질 디버깅에 사용됩니다. 또한 카메라 모듈 유형에 따라 여러 카메라의 동시 모니터링도 지원합니다.
tcnncameraapp에서 제공하는 옵션은 다음 표와 같습니다.
 
| 이름              | 옵션    | 범위      | 기본값       | 예시           | 설명                                  |
| ------------------| --------| ----------| ------------| ---------------| --------------------------------------|
| 사용 정보         | -?      |     -     |             | -?             | 사용 정보 표시                        |
| 입력 경로         | -p      |     -     | /dev/video0 | -p /dev/video0 | 입력 경로 지정                        |
| 출력 경로         | -P      |     -     | /dev/overlay| -P /dev/overlay| 출력 경로 지정                        |
| 입력 너비         | -w      | 최대 2560 | 1920        | -w 2560        | 입력 너비 지정                        |
| 입력 높이         | -h      | 최대 1440 | 1080        | -h 1080        | 입력 높이 지정                        |
| 출력 너비         | -W      | 최대 1920 | 1920        | -W 1920        | 출력 너비 지정                        |
| 출력 높이         | -H      | 최대 720  | 720         | -H 720         | 출력 높이 지정                        |
| 출력 위치 X       | -X      | 최대 1920 | 0           | -X 960         | 출력의 X 좌표 지정                    |
| 출력 위치 Y       | -Y      | 최대 720  | 0           | -Y 360         | 출력의 Y 좌표 지정                    |
<p align="center"><strong>표 2.1 카메라 테스트 애플리케이션 옵션</strong></p><br/>
 
**참고**: 출력 너비와 X 위치의 합은 1920을 초과해서는 안 되며, 출력 높이와 Y 위치의 합은 720을 초과해서는 안 됩니다.
 
애플리케이션 실행 결과는 다음과 같습니다:
```
root@ai-g-topst:~# tcnncameraapp
------------------ Parameter Info ------------------
[Common]Input Path             : /dev/video0
[Common]Output Path            : /dev/overlay
[Common]Input Width            : 1280
[Common]Input Height           : 720
[Common]Output Width           : 800
[Common]Output Height          : 480
[Common]Output Position X      : 0
[Common]Output Position Y      : 0
[Debug] Debug Mode             : off
---------------------- Usage ----------------------
 
[INFO] [SCALER_API] scaler /dev/scaler1 open() success:, fd:5
[INFO] [CAMERA_API] [CameraSetConfig] mmap idx : 0, len : 3686400, off :        0, reserved : 86b00000
[INFO] [CAMERA_API] [CameraSetConfig] mmap idx : 1, len : 3686400, off :   384000, reserved : 86f00000
[INFO] [CAMERA_API] [CameraSetConfig] mmap idx : 2, len : 3686400, off :   708000, reserved : 87300000
```
 
tcnncameraapp을 실행한 후, 시스템은 실시간 카메라 미리보기를 위해 메모리 매핑(mmap)을 사용하여 여러 프레임 버퍼를 할당합니다. 각 버퍼는 효율적인 비디오 스트리밍 및 렌더링을 위해 인덱싱되고 특정 물리적 주소 공간에 매핑됩니다.
<br/><br/><br/>
 
## 2.3 tcnputestapp
---
tcnputestapp은 AI-G 플랫폼에서 신경망 처리 장치(NPU)의 기본 기능을 검증하는 샘플 애플리케이션입니다. tcndnpulib 라이브러리를 활용하여 사전 컴파일된 신경망 모델로 NPU 실행을 직접 테스트합니다. 이 애플리케이션은 주로 카메라나 디스플레이 개입 없이 NPU의 내부 검증, 디버깅 및 성능 테스트를 위해 사용됩니다.
tcnputestapp에서 제공하는 옵션은 다음 표와 같습니다.
 
| 이름           | 옵션   | 범위      | 기본값       | 예시                     | 설명                                  |
| ---------------| -------| ----------| ------------| -------------------------| --------------------------------------|
| 사용 정보      | -?     |     -     |      -      | -?                       | 사용 정보 표시                        |
| NPU 번호       | -d     |    0, 1   |      0      | -d 0 / -d 1 / -d 0 1     | 네트워크의 NPU 인덱스 지정            |
| 네트워크 경로  | -n     |     -     | /usr/share/yolov5s_quantized| -n /usr/share/mobilenetv2_10_quantized/   | 테스트할 신경망 지정. 두 개의 NPU가 선택된 경우 동일한 신경망 경로를 가짐 |
| 테스트 횟수    | -t     | -         | 1           | -t 100                   | 신경망 테스트 횟수 지정               |
<p align="center"><strong>표 2.2 NPU 테스트 애플리케이션 옵션</strong></p><br/>
 
애플리케이션 실행 결과는 다음과 같습니다:
```
root@ai-g-topst:~# tcnputestapp
npu 0 open success
========================
   NPU Device Info
========================
NPU product id: 0xED9E
NPU major ver : 0x2
NPU minor ver : 0x0
NPU ecc       : 0x1
NPU core num  : 0x2
========================
 
NPU0 Network: /usr/share/yolov5s_quantized
NPU0 Performance Statistics for 1 runs
NPU0 Elapsed Time  (ms) - Min: 14.20     Max: 14.20     Avg: 14.20
NPU0 DMA Count  (@pclk) - Min: 992881    Max: 992881    Avg: 992881.00
NPU0 Comp Count (@pclk) - Min: 2218197   Max: 2218197   Avg: 2218197.00
NPU0 Utilization    (%) - Min: 29.30     Max: 29.30     Avg: 29.30
 
npu 0 close
========================
npu test: Success!
```
 
tcnputestapp을 실행한 후, NPU가 초기화되고 기본 YOLOv5s 양자화 모델을 사용하여 추론을 수행합니다. 실행 시간, DMA/연산 사이클 수, 활용률과 같은 성능 지표가 보고되어 NPU 기능을 빠르게 검증할 수 있습니다.