# 1. はじめに
---
このドキュメントでは、AI-G SDKに含まれるサンプルおよびテストアプリケーションの使用方法について説明します。これらのアプリケーションは、ユーザーがAI-GのオンボードNPUを使用したAI推論機能を理解し、評価できるように設計されています。
このドキュメントには、以下の情報が含まれています：
- サンプルアプリケーション
  - tcnnapp
  - tcnncameraapp
  - tcnputestapp
<br/><br/><br/><br/>
 
 
# 2. サンプルアプリケーション
---
このセクションでは、AI-G SDKで提供される3つのサンプル/テストアプリケーションについて説明します。各アプリケーションは、ユーザーがAI-GのAI機能を評価および活用できるように設計されています。アプリケーションは、NPU推論テストやリアルタイムカメラ入力など、さまざまなシナリオをカバーしています。
<br/><br/><br/>
 
## 2.1 tcnnapp
---
tcnnappは、AI-Gプラットフォーム上でNPUを使用して画像ベースの推論を実行する方法を示すサンプルAIアプリケーションです。さまざまな入出力モードをサポートし、YOLOv5sやMobileNetv2などの事前学習済みモデルを使用した物体検出を紹介します。
<br/><br/>
 
### ユースケース 1. 基本的なファイル対ファイル推論
このケースでは、ローカル画像ファイルに対して推論を実行し、結果を出力ファイルに保存する方法を示します。これは、カメラやディスプレイハードウェアを使用せずに基本的な機能テストやモデル検証を行うのに役立ちます。
推論を行うには、以下のコマンドを入力します：
```
$ tcnnapp -i file -p test.png -o file -P result.png
```
 
このコマンドは、入力画像ファイル (test.png) を使用してtcnnappを実行し、推論結果を出力ファイル (result.png) に保存します。モデルを指定しない場合、アプリケーションは自動的にデフォルトの量子化モデルであるYOLOv5sとMobileNetv2を使用します。
結果は以下の通りです：
<p align="center"><img src="https://raw.githubusercontent.com/topst-development/Documentation/refs/heads/main/Assets/TOPST%20AI-G/Available%20Applications/Figure%201.%20Inference%20Result.png"></p>
<p align="center"><strong>図 2.1 推論結果 </strong></p>
<br/><br/>
 
### ユースケース 2. カメラとディスプレイを使用したリアルタイム推論
このケースでは、接続されたMIPI CSIカメラとMIPI DSIディスプレイを使用してtcnnappを使用し、リアルタイムAI推論を実行して結果を視覚化する方法を示します。アプリケーションは、カメラからのライブビデオ入力をストリーミングし、NPU上でデフォルトの量子化モデル (YOLOv5sおよびMobileNetv2) を使用してリアルタイム推論を実行し、結果を画面に表示します。
デバイスの接続は以下の通りです：
<p align="center"><img src="https://raw.githubusercontent.com/topst-development/Documentation/refs/heads/main/Assets/TOPST%20AI-G/Available%20Applications/Figure%202.%20Device%20Connection.png" width="600"></p>
<p align="center"><strong>図 2.2 AI-Gでのカメラとディスプレイの接続 </strong></p><br/>
 
デバイスを接続した後、以下のコマンドを入力します：
```
$ tcnnapp -i camera -o display
```
このコマンドは、CSIカメラを入力として使用してリアルタイム推論を開始します。キャプチャされたビデオフレームは、物体検出および分類タスクのためにNPUに供給されます。
バウンディングボックス、クラスラベル、信頼度スコアなどの推論結果は、出力フレームに直接レンダリングされます。
これらの注釈付きフレームは5インチDSIディスプレイにリアルタイムで表示され、即座に視覚的なフィードバックを提供します。
 
視覚的な出力に加えて、システムはCPU使用率、NPU使用率、メモリステータスなどの主要なパフォーマンス指標をログに記録し、シリアルコンソールまたはリモートインターフェースを介して監視できます。
 
結果は以下の通りです：
<p align="center"><img src="https://raw.githubusercontent.com/topst-development/Documentation/refs/heads/main/Assets/TOPST%20AI-G/Software/NPU%20development/AI-G%20NPU%20toolkit/6.%20Sample%20Applictation.png" width="500"></p>
<p align="center"><strong>図 2.3 推論結果 </strong></p><br/>
 
<br/><br/>
 
### ユースケース 3. カメラとRTPMを使用したリアルタイム推論
このケースでは、MIPI CSIカメラを入力として、リアルタイムパフォーマンスモニター (RTPM) を出力方法として使用してtcnnappを使用する方法を示します。このアプリケーションは、カメラからのライブビデオ入力をストリーミングし、NPU上でデフォルトの量子化モデル (YOLOv5sおよびMobileNetv2) を使用してリアルタイム推論を実行し、結果をRTPMを介してPCに送信して視覚化およびパフォーマンス監視を行います。
RTPMツールキットは、PC環境でAI-Gからの出力を監視するためにPythonで開発されたGUIベースのツールです。推論結果だけでなく、CPU、NPU、メモリ使用量などのシステムパフォーマンスメトリクスも観察できます。
 
**注**: RTPMの詳細については、ソフトウェアセクションのRTPM.mdを参照してください。
 
デバイスの接続は以下の通りです：
<p align="center"><img src="https://raw.githubusercontent.com/topst-development/Documentation/refs/heads/main/Assets/TOPST%20AI-G/Available%20Applications/Figure%204.%20Camera%20and%20RTPM%20Communication%20via%20AI-G.png"width="900"></p>
<p align="center"><strong>図 2.4 AI-Gを介したカメラとRTPMの通信 </strong></p><br/>
 
カメラを接続した後、以下のコマンドを入力します：
```
$ tcnnapp -i camera -o rtpm
```
 
このコマンドは、CSIカメラを入力として使用してリアルタイム推論を開始します。検出された物体や分類ラベルなどの推論結果はホストPCに送信され、RTPMインターフェースを介して視覚化されます。
推論出力に加えて、RTPMはCPU使用率、NPU負荷、メモリ使用量などのシステムパフォーマンスメトリクスもリアルタイムで表示します。
結果は以下の通りです：
<p align="center"><img src="https://raw.githubusercontent.com/topst-development/Documentation/refs/heads/main/Assets/TOPST%20AI-G/Available%20Applications/Figure%205.%20Inference%20Result.png"width="1600"></p>
<p align="center"><strong>図 2.5 推論結果 </strong></p>
<br/><br/>
 
### ユースケース 4. RTPM入出力を使用した推論
このケースでは、RTPMを介してホストPCからストリーミングされた入力画像を使用して推論を実行し、推論結果を同じRTPMインターフェースを介して表示するためにPCに送り返す方法を示します。入力データは画像またはビデオにすることができます。
RTPMを実行するには、ソフトウェアセクションのRTPM.mdドキュメントを参照してください。その後、以下のコマンドを入力します：
```
$ tcnnapp -i rtpm -o rtpm
```
このコマンドは、RTPMを入力と出力の両方として使用してtcnnappを実行します。データはRTPMを介してホストPCから送信され、AI-Gボード上のNPUによって処理され、推論結果はPCに送り返されてRTPMインターフェースを介して表示されます。
結果は以下の通りです：
<p align="center"><img src="https://raw.githubusercontent.com/topst-development/Documentation/refs/heads/main/Assets/TOPST%20AI-G/Available%20Applications/Figure%206.%20Inference%20Result.png"></p>
<p align="center"><strong>図 2.6 推論結果 </strong></p>
<br/><br/><br/>
 
## 2.2 tcnncameraapp
---
tcnncameraappは、AI-Gプラットフォームでサポートされているカメラモジュールをテストおよびプレビューできるサンプルアプリケーションです。Video4Linux2 (V4L2) フレームワーク上に構築されており、接続されたMIPI CSIインターフェースとDSIディスプレイを介したリアルタイムカメラプレビューを可能にします。
このアプリケーションは主に、カメラ機能の検証、ディスプレイ出力のテスト、および画像信号品質のデバッグに使用されます。また、カメラモジュールのタイプに応じて、複数のカメラの同時監視もサポートしています。
tcnncameraappによって提供されるオプションは、以下の表に示されています。
 
| 名前              | オプション | 範囲      | デフォルト   | 例             | 説明                                  |
| ------------------| --------| ----------| ------------| ---------------| --------------------------------------|
| 使用情報          | -?      |     -     |             | -?             | 使用情報を表示する                    |
| 入力パス          | -p      |     -     | /dev/video0 | -p /dev/video0 | 入力パスを指定する                    |
| 出力パス          | -P      |     -     | /dev/overlay| -P /dev/overlay| 出力パスを指定する                    |
| 入力幅            | -w      | 2560まで  | 1920        | -w 2560        | 入力の幅を指定する                    |
| 入力高さ          | -h      | 1440まで  | 1080        | -h 1080        | 入力の高さを指定する                  |
| 出力幅            | -W      | 1920まで  | 1920        | -W 1920        | 出力の幅を指定する                    |
| 出力高さ          | -H      | 720まで   | 720         | -H 720         | 出力の高さを指定する                  |
| 出力位置 X        | -X      | 1920まで  | 0           | -X 960         | 出力のX座標を指定する                 |
| 出力位置 Y        | -Y      | 720まで   | 0           | -Y 360         | 出力のY座標を指定する                 |
<p align="center"><strong>表 2.1 カメラテストアプリケーションオプション</strong></p><br/>
 
**注**: 出力幅とそのX位置の合計は1920を超えてはならず、出力高さとそのY位置の合計は720を超えてはなりません。
 
アプリケーションの実行結果は以下の通りです：
```
root@ai-g-topst:~# tcnncameraapp
------------------ Parameter Info ------------------
[Common]Input Path             : /dev/video0
[Common]Output Path            : /dev/overlay
[Common]Input Width            : 1280
[Common]Input Height           : 720
[Common]Output Width           : 800
[Common]Output Height          : 480
[Common]Output Position X      : 0
[Common]Output Position Y      : 0
[Debug] Debug Mode             : off
---------------------- Usage ----------------------
 
[INFO] [SCALER_API] scaler /dev/scaler1 open() success:, fd:5
[INFO] [CAMERA_API] [CameraSetConfig] mmap idx : 0, len : 3686400, off :        0, reserved : 86b00000
[INFO] [CAMERA_API] [CameraSetConfig] mmap idx : 1, len : 3686400, off :   384000, reserved : 86f00000
[INFO] [CAMERA_API] [CameraSetConfig] mmap idx : 2, len : 3686400, off :   708000, reserved : 87300000
```
 
tcnncameraappを起動した後、システムはリアルタイムカメラプレビューのためにメモリマッピング (mmap) を使用して複数のフレームバッファを割り当てます。各バッファはインデックス付けされ、効率的なビデオストリーミングとレンダリングのために特定の物理アドレス空間にマッピングされます。
<br/><br/><br/>
 
## 2.3 tcnputestapp
---
tcnputestappは、AI-Gプラットフォーム上のニューラルプロセッシングユニット (NPU) の基本機能を検証するサンプルアプリケーションです。tcndnpulibライブラリを使用して、コンパイル済みのニューラルネットワークモデルでNPU実行を直接テストします。このアプリケーションは主に、カメラやディスプレイの関与なしに、NPUの内部検証、デバッグ、およびパフォーマンステストを目的としています。
tcnputestappによって提供されるオプションは、以下の表に示されています。
 
| 名前           | オプション | 範囲      | デフォルト   | 例                       | 説明                                  |
| ---------------| -------| ----------| ------------| -------------------------| --------------------------------------|
| 使用情報       | -?     |     -     |      -      | -?                       | 使用情報を表示する                    |
| NPU番号        | -d     |    0, 1   |      0      | -d 0 / -d 1 / -d 0 1     | ネットワークのNPUインデックスを指定する |
| ネットワークパス| -n     |     -     | /usr/share/yolov5s_quantized| -n /usr/share/mobilenetv2_10_quantized/   | テストするニューラルネットワークを指定する。2つのNPUが選択されている場合、それらは同じニューラルネットワークパスを持つ |
| テスト回数     | -t     | -         | 1           | -t 100                   | ニューラルネットワークテストの回数を指定する |
<p align="center"><strong>表 2.2 NPUテストアプリケーションオプション</strong></p><br/>
 
アプリケーションの実行結果は以下の通りです：
```
root@ai-g-topst:~# tcnputestapp
npu 0 open success
========================
   NPU Device Info
========================
NPU product id: 0xED9E
NPU major ver : 0x2
NPU minor ver : 0x0
NPU ecc       : 0x1
NPU core num  : 0x2
========================
 
NPU0 Network: /usr/share/yolov5s_quantized
NPU0 Performance Statistics for 1 runs
NPU0 Elapsed Time  (ms) - Min: 14.20     Max: 14.20     Avg: 14.20
NPU0 DMA Count  (@pclk) - Min: 992881    Max: 992881    Avg: 992881.00
NPU0 Comp Count (@pclk) - Min: 2218197   Max: 2218197   Avg: 2218197.00
NPU0 Utilization    (%) - Min: 29.30     Max: 29.30     Avg: 29.30
 
npu 0 close
========================
npu test: Success!
```
 
tcnputestappを実行した後、NPUは初期化され、デフォルトのYOLOv5s量子化モデルを使用して推論を実行します。実行時間、DMA/計算サイクルカウント、使用率などのパフォーマンスメトリクスが報告され、NPU機能の迅速な検証を提供します。